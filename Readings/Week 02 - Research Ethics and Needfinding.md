# Week 3

> Ten questions on each test will be based on these readings. From the perspective of the test, your emphasis in reading these papers should be in getting a sufficient understanding of the material to answer high-level questions about the paper, as well as to be able to find answers quickly for more specific questions.

## Chapter 4: Scientific Foundations

> MacKenzie, I.S. (2013). Chapter 4: Scientific Foundations. Human-Computer Interaction: An Empirical Research Perspective. (pp. 121-152). Waltham, MA: Elsevier.

### what is research?
- To rise above conjecture, we demand evidence—evidence meeting a standard of credibility
such that the statement is beyond dispute. Providing such credibility is the goal of
research

There are three different definitions:

1. An exercise as simple as careful or diligent search
2. Collecting information about a particular subject
3. Investigation or experimentation aimed at the discovery and interpretation of facts and revision of accepted theories or laws in light of new facts

- In HCI research we don’t prove things; we gather facts and formulate and test evidence.
- Research, according to the third definition, involves discovery, interpretation, and revision.
- Research has a critical purpose: to extend, refine, or revise the existing body of knowledge in the field; this is achieved through publication.
- Though citations the body of research takes shape, the insights and lessons from early research inform and guide later research.
- Research must be reproducible. The reproducibility standard enforces a process for conducting and writing about the research that ensures sufficient detail is included to allow the results to be replicated.
- Engineers and designers create products that strive to bring together the best in form (design emphasis) and function (engineering emphasis). Engineers work in a world where the focus is on designing complete systems or products whereas research tends to be narrowly focused. Research tends to be small in scope where results are incremental not monumental. While a prototype is used to access alternatives in product development, a researcher's prototype is an early mock-up of an idea which is unlikely to directly appear in a product.
- Furthermore, the march forward for research is at a slower pace, without the shackles of deadlines.

Tim Brown CEO of IDEO design firm on prototypes:

> Prototypes should command only as much time, effort, and investment as are needed to generate useful feedback and evolve an idea. The more “finished” a prototype seems, the less likely its creators will be to pay attention to and profit from feedback. The goal of prototyping isn’t to finish. It is to learn about the strengths and weaknesses of the idea and to identify new directions that further prototypes might take

- While engineers and designers strive to build better systems or products, in the broadest sense, researchers provide the raw materials and processes engineers and designers work with.

### Empirical Research


Various definitions of empirical research:

1. Originating in or based on observation or experience
2. Relying on experience or observation alone, often without due regard for system and theory
3. Capable of being verified or disproved by observation or experiment


### Empirical Research Methods

Three common research methods in HCI which are empirical:

1. Observational method:
   - Encompasses a collection of common techniques used in HCI research; this qualitative approach tends to achieve relevance while sacrificing precision, in HCI, this is the why or how of the interaction, as opposed to the what, where, or when
   - Includes interviews, field investigations, contextual inquiries, case studies, field studies, focus groups, think aloud protocols, storytelling, walkthrough, cultural probes, etc.
2. Experimental method:
   - The scientific method, is where knowledge is acquired through controlled experiments conducted in laboratory settings
   - HCI experiments involve humans, so the methodology employed is borrowed from experimental psychology, a field with a long history of research involving humans. In a sense, HCI is the beneficiary of this more mature field. 
   - It is naïve to think we can simply choose to focus on the experimental method and ignore qualities of interaction that are outside the scope of the experimental procedure. A full and proper user study—an experiment with human participants— involves more than just measuring and analyzing human performance
   - The relationship between the independent variable and the dependent variable is one of cause and effect; cause-and-effect conclusions are not possible in research using the observational method or the correlational method
3. Correlational method:
   - Involves looking for relationships between variables, provides a balance between relevance and precision
   - Characterized by quantification since the magnitude of variables must be ascertained
   - Data may be collected through observation, interviews, on-line surveys, questionnaires, or measurement
   - Data obtained using correlational methods are circumstantial, not causal

### Observation and Measure
- Observation is the precursor to measurement, and if the investigator is the observer, then measurements are collected manually. This could involve using a log sheet or notebook to jot down the number of events of interest observed. Events of interest might include the number of times the user clicked a button or moved his or her hand from the keyboard to the mouse.
- More often in empirical research, the task of observing is delegated to the apparatus—the computer. Of course, this is a challenge in some situations. As an example, if the interaction is with a digital sports watch or automated teller machine (ATM), it is not possible to embed data collection software in the apparatus. Even if the apparatus is a conventional desktop computer, some behaviors of interest are
difficult to detect

### Measurement Scales - Types of Data

#### Nominal Data 
-  A measurement on the nominal scale involves arbitrarily assigning a code to an attribute or a category. The measurement is so arbitrary that the code needn’t be a number (although it could be). Examples are automobile license plate numbers, codes for postal zones, job classifications, military ranks, etc.
- Nominal data identify mutually exclusive categories. Membership or exclusivity is meaningful, but little else. The only relationship that holds is equivalence, which exists between entities in the
same class. Nominal data are also called categorical data.
- Nominal data are often used with frequencies or counts—the number of occurrences of each attribute

#### Ordinal data
- Ordinal scale measurements provide an order or ranking to an attribute. The attribute
can be any characteristic or circumstance of interest. 
- For example, users might be asked to try three global positioning systems (GPS) for a period of time and then rank the systems by preference: first choice, second choice, third choice. Or users
could be asked to consider properties of a mobile phone such as price, features, coolappeal, and usability, and then order the features by personal importance. 
- The main limitation of ordinal data is that the interval is not intrinsically equal between successive points on the scale. In the example just cited, there is no innate sense of how much more important usability is over cool-appeal or whether the difference is greater or less than that between, for example, cool-appeal and price.
- Ordinal data are slightly more sophisticated than nominal data since comparisons of greater than or less than are possible. However, it is not valid to compute the mean of ordinal data.

#### Interval Data
- Moving up in sophistication, interval data have equal distances between adjacent values. However, there is no absolute zero. The classic example of interval data is temperature measured on the Fahrenheit or Celsius scale. 
- Unlike ordinal data, it is meaningful to compute the mean of interval data, for example, the mean mid-day temperature during the month of July. Ratios of interval data are not meaningful, however. For example, one cannot say that 20°C is twice as warm as 10°C
-  One remedy for non-equal gradations in Likert-scale response items is simply to instruct respondents to interpret the items as equally spaced


#### Ratio Data
- Ratio-scale measurements are the most sophisticated of the four scales of measurement. Ratio data have an absolute zero and support a myriad of calculations
- Ratio data can be added, subtracted, multiplied, divided; means, standard deviations, and variances can be computed. In HCI, the most common ratio-scale measurement is time—the time to complete a task.
- But generally, all physical measurements are also ratio-scale, such as the distance or velocity of a cursor as it moves across a display, the force applied by a finger on a touchscreen, and so on. Many social variables are also ratio-scale, such as a user’s age or years of computer experience.

### Research Questions
- The notion of posing or answering questions seems simple enough, but this is tricky because of the human element. Unlike an algorithm operating on a data set, where the time to search, sort, or whatever is the same with each try, people exhibit variability in their actions.
- Create informal questions and  then move forward from the loose and informal questions above to questions more suitable for empirical and experimental enquiry.

### Internal and External Validity
- At this juncture we are in a position to consider two important properties of experimental research: internal validity and external validity
- Internal Validity
	- Internal validity (definition) is the extent to which an effect observed is due to the test conditions. For the example, an effect is simply the difference in entry speed between the new technique and QSK. If we conduct an experiment to measure and compare the entry speed for the two techniques, we want confidence that the difference observed was actually due to inherent differences between the techniques. Internal validity captures this confidence. 
	- As already noted, this question is not testable in an empirical sense. Attempts to answer it directly are fraught with problems, because we lack a methodology to observe and measure “better than”
- External Validity
	- Answerable with high accuracy (that’s good!). The question is testable, which means we can craft a methodology to answer it through observation and measurement. Unfortunately, the narrow scope of the question brings different problems. Focusing on entry speed is fine, but what about other aspects of the interaction?
	- External validity (definition) is the extent to which experimental results are generalizable to other people and other situations. Generalizable clearly speaks to breadth in Figure 4.8. To the extent the research pursues broadly framed questions, the results tend to be broadly applicable. But there is more. Research results that apply to “other people” imply that the participants involved were representative of a larger intended population
- Unfortunately, there is no universal remedy for the tension between internal and external validity. At the very least, one must acknowledge the limitations. Formulating conclusions that are broader than what the results suggest is sure to raise the ire of reviewers. We can strive for the best of both worlds with a simple approach, however. Posing multiple narrow (testable) questions that cover the range
of outcomes influencing the broader (untestable) questions will increase both internal and external validity.

### Comparitive Evaluations
-  In other words, a new user interface or interaction technique is designed and implemented and then compared with one or more alternative designs to determine which is faster, more accurate, less confusing, more preferred by users, etc. 
- A controlled experiment must include at least one independent variable and the independent variable must have atleast two levels or test conditions. Comparison, then, is inherent in research following the experimental method discussed earlier.
- **Add Baseline** - The idea of including an established design as a baseline condition is particularly appealing. There are two benefits. First, the baseline condition serves as a check on the methodology. Baseline conditions are well traveled in the research literature, so results in a new experiment are expected to align with previous results. Second, the baseline condition allows results to be compared with other studies

### Relationships: circumstantial and causal

- looking for and explaining interesting relationships is part of what we do in HCI research
- Finding a causal relationship in an HCI experiment yields a powerful conclusion. If the human response measured is vital in HCI, such as the time it takes to do a common task, then knowing that a condition tested in the experiment reduces this time is a valuable outcome. If the condition is an implementation of a novel idea and it was compared with current practice, there may indeed be reason to celebrate
   - Causal relationships emerge from controlled experiments. Looking for a causal relationship requires a study where, among other things, participants are selected randomly from a population and are randomly assigned to test conditions
   - Cause and effect conclusions are not possible in certain types of controlled experiments. If the variable manipulated is a naturally occurring attribute of participants, then cause and effect conclusions are unreliable.
- Many relationships are circumstantial. They exist, and they can be observed, measured, and quantified. But they are not causal, and any attempt to express the relationship as such is wrong. The classic example is the relationship between smoking and cancer. Suppose a research study tracks the habits and health of a large number of people over many years. This is an example of the correlational method of
research mentioned earlier. 

### Tips

Tips for finding an interesting research topic:

1. Think small
2. Replicate
3. Know the literature
4. Think inside the box

Some terms from this section:

- **User study** - an experiment in HCI
- **Empirical research** - encompassing both experimental and non-experimental methodologies
- **Facts** - the building blocks of evidence and is what we seek in experimental research
- **Theory** - a hypothesis assumed for the sake of argument or investigation; becomes a scientifically accepted body of principles that explain phenomena once confirmed through research
- **Law** - more specific, constraining, formal, and binding; a relationship or phenomenon that is invariable under given conditions
- **Fitt's law** - body of work originally in human motor behavior that is widely used in HCI; includes equations for predicting the time to do point-select tasks
- **Archived** - research paper is added to the collection of related work accessible to other researchers throughout the world; this is the final step in publication
- **Patent** - is also a publication, describes previous related work (prior art), how the invention addresses a need, and the best mode of implementation
- **H-index** - the most accepted single measure of the impact of a researcher's publication record
- **Controlled experiment** - requires at least two variables: a manipulated variable and a response variable
- **Manipulated variable** - typically a property of an interface or interaction technique that is presented to participants in different configurations (also known as an independent variable)
- **Response variable** - a property of human behavior that is observable, quantifiable, and measurable (also know as the dependent variable)
- **Usability evaluation** - involves accessing a single user interface for strengths and weaknesses (not controlled) whereas a user study is controlled
- **Internal validity** - is the extent to which an effect observed is due to the test conditions
- **External validity** - is the extent to which experimental results are generalizable to other people and other situations
- **Ecological validity** - refers to the methodology (using materials, tasks and situations typical of the real world), whereas external validity refers to the outcome (obtaining results that generalize to a broad range of people and situations)

## Survey Research In HCI

A survey is a method of gathering information by asking questions to a subset of people, the results of which can be generalized to the wider target population.

### Use of Survey


- Get demographic or psychographic information to characterize a population
- Get feedback on people’s experiences with a product, service, or application
- Collect people’s attitudes and perceptions toward an application in the context of usage
- Understand people’s intents and motivations for using an application
- Quantitatively measure task success with specific parts of an application
- Capture people’s awareness of certain systems, services, theories, or features
- Compare people’s attitudes, experiences, etc. over time and across dimensions

* Surveys do not allow for observation of the respondents’ context or follow-up questions. When conducting research into precise behaviors, underlying motivations, and the usability of systems, then other research methods may be more appropriate or needed as a complement.
* When used appropriately, surveys can help inform application and user research
strategies and provide insights into users’ attitudes, experiences, intents, demographics, and psychographic characteristics.

### Bit of History

- At the emergence of contemporary psychology, Francis Galton pioneered the use of questionnaires to investigate the nature vs. nurture debate and differences between
humans, the latter of which evolved into the field of psychometrics (Clauser, 2007)

### Surveys are appropriate for obtaining:

1. Attitudes - Surveys can accurately measure and reliably represent attitudes and perceptions of a population. Example, customer satisfaction.
2. Intent - Surveys can collect peoples’ reasons for using an application at a specific time, allowing researchers to gauge the frequency across different objectives.
3. Task success - a survey can be used to reliably quantify levels of success. Ex execute and report on a task
4. User experience feedback - Collecting open-ended feedback about a user’s experience can be used to understand the user’s interaction with technology.
5. User characteristics - Collecting open-ended feedback about a user’s experience can be used to understand the user’s interaction with technology.
6. Interactions with technology - Surveys can be used to understand more broadly how people interact with technology and how technology influences social interactions
7. Awareness - Surveys can also help in understanding people’s awareness of existing technologies or specific application feature
8. Comparisons - Surveys can be used to compare users’ attitudes, perceptions, and experiences across user segments, time, geographies, and competing applications and between experimental and control versions

Researchers should avoid using surveys when trying to obtain:

1. Precise behaviors - While respondents can be asked to self-report their behaviors, gathering this information from log data, if available
2. Underlying motivations - People often do not understand or are unable to explain why they take certain actions or prefer one thing over another.
3. Usability evaluations - Surveys are inappropriate for testing specific usability tasks and understanding of tools and application elements.


* Better to use survey with other methods as it helps in initial and intermediate stages to verify on the problem.

### Stages in Survey

1. **Research goals and constructs** - When the survey-appropriate research goals have been identified, they should be matched to constructs, i.e., unidimensional attributes that cannot be directly observed. The identified constructs should then be converted into one or multiple survey questions. Furthermore, a technique called cognitive pretesting can be used to determine whether respondents are interpreting the constructs as intended by the researcher.
2. **Population and sampling**
   - Key to effective survey research is determining who and how many people to survey. In order to do this, the survey’s population, or set of individuals that meet certain criteria, and to whom researchers wish to generalize their results must first be defined.  
   - However, if the sampling frame systematically excludes certain types of people (e.g., very dissatisfied or disengaged users), the survey will suffer from coverage error and its responses will misrepresent the population
   - Probability or random sampling is considered the gold standard because every person in the sampling frame has an equal, nonzero chance of being chosen for the sample
   - Especially when targeting small populations (e.g., users of a specialized enterprise product or experts in a particular field) or investigating sensitive or rare behavior. In these situations, researchers may use non-probability sampling methods such as volunteer opt-in panels, unrestricted self-selected surveys (e.g., links on blogs and social networks), snowball recruiting (i.e., asking for friends of friends), and convenience samples (i.e., targeting people readily available, such as mall shoppers) (Couper, 2000).
   - There are various formulas for calculating the target sample size. Figure 4, based on Krejcie and Morgan’s formula (1970), shows the appropriate sample size, given the population size, as well as the chosen margin of error and confidence level for your survey
3. **Questionnaire design and biases**
   - Upon establishing the constructs to be measured and the appropriate sampling method, the first iteration of the survey questionnaire can be designed
   - Poor questionnaire design may introduce measurement error, defined as the deviation of the respondents’ answers from their true values on the measure
   - Closed vs Open ended, Single choice vs Multiple Choice, Ranking vs Rating, Unipolar (0-5) vs Bipolar (-1 to 5). Also When using a rating scale, the inclusion of a midpoint should be considered
   - **Biases in Questions**
      - Satisficing occurs when respondents use a suboptimal amount of cognitive effort to answer questions.
      - Acquiecence Bias - When presented with agree/disagree, yes/no, or true/false statements, some respondents are more likely to concur with the statement independent of its substance.
      - Social desirability occurs when respondents answer questions in a manner they feel will be positively perceived by others.
      - Response order bias is the tendency to select the items toward the beginning (i.e., primacy effect) or the end (i.e., recency effect) of an answer list or scale.
      - Question Order Bias - Order effects also apply to the order of the questions in surveys. Each question in a survey has the potential to bias each subsequent question by priming respondents.
      - Leveraging Established Questionnaires: An alternative to constructing a brand new questionnaire is utilizing questionnaires developed by others. These usually benefit from prior validation and allow researchers to compare results with other studies that used the same questionnaire.
      - Researchers should also take into account their survey’s visual design, since specific choices, including the use of images, spacing, and progress bars, may unintentionally bias respondents. 
      - Survey questions can be presented one per page, multiple per page, or all on one page. Research into pagination effects on completion rates is inconclusive.
      - While progress bars are generally preferred by respondents and are helpful for short surveys, their use in long surveys or surveys with skip logic can be misleading and intimidating.
4. Review and survey pretesting
   - Cognitive Pretesting - To conduct a cognitive pretest, a small set of potential respondents is invited to participate in an in-person interview where they are asked to take the survey while using the think-aloud protocol (similar to a usability study).
   - To conduct a cognitive pretest, a small set of potential respondents is invited to participate in an in-person interview where they are asked to take the survey while using the think-aloud protocol (similar to a usability study).
   - A cognitive pretest assesses question interpretation, construct validity, and comprehension of survey terminology and calls attention to missing answer options or entire questions
      - Read the entire question and describe it in your own words.
      - Select or write an answer while explaining your thought process.
      - Describe any confusing terminology or missing answer choices.
   - Piloting the survey with a small subset of the sample will help provide insights that cognitive pretests alone cannot. Through field testing, the researcher can assess the success of the sampling approach, look for common break-off points and long completion times, and examine answers to openended questions.
5. Implementation and launch
   - When all questions are finalized, the survey is ready to be fielded based on the chosen sampling method. Respondents may be invited through e-mails to specifically named persons.
   - **Piping Behavioral Data into Surveys** - Some platforms support the ability to combine survey responses with other log data, which is referred to as piping. Self-reported behaviors, such as frequency of use, feature usage, tenure, and platform usage, are less valid and reliable compared to generating the same metrics through log data.
   - **Monitoring Survey Paradata** - Survey paradata is data collected about the survey response process, such as the devices from which the survey was accessed, time to survey completion, and various response-related rates. By monitoring such metrics, the survey researcher can quickly apply improvements before the entire sample has responded to the survey.
   - **Maximizing Response Rates** - In order to gather enough responses to represent the target population with the desired
   level of precision, response rates should be maximized. The initial request with the survey on week one, a reminder postcard on week two, a replacement survey to non-respondents on week four, and a second replacement survey to non-respondents by certified mail on week seven.
6. Data analysis and reporting
   - **Data Preparation and Cleaning** - Cleaning and preparing survey data before conducting a thorough analysis are
   essential to identify low-quality responses that may otherwise skew the results. When taking a pass through the data, survey researchers should look for signs of poor-quality responses. Duplicate responses, Speeders, Straight-liners and other questionable patterns, Missing data and break-offs, Missing data and break-off, Outliers and Inadequate open-ended responses.
   - **Analysis of Closed-Ended Responses** 
      - By looking at measures such as the frequency distribution, central tendency.
      - While descriptive statistics only describe the existing data set, inferential statistics can be used to draw inferences from the sample to the overall population in question.
      - Either the margin of error or the confidence interval of the sample’s data needs to be determined for such estimation
      - A confidence interval thus represents the estimated range of a population’s mean at a certain confidence level.
      - Hypothesis testing determines the probability of a hypothesis being true when comparing groups
         - Bivariate correlations.
         - Linear regression analysis indicates the proportion of variance in a continuous dependent variable that is explained by one or more independent variables.
         - Logistic regression, Decision Tree, Factor Analysis and Cluster Analysis. 
   - **Analysis of Open-Ended Comments** - The analysis of open-ended survey responses can be derived from the method of grounded theory. An interpretive method, referred to as coding, is used to organize and transform qualitative data from open-ended questions to enable further quantitative analysis.
      - In most cases, as questions are customized to each individual survey, the researcher needs to establish the coding system using a deductive or an inductive approach.
   - **Assessing Representativeness** - A key criterion in any survey’s quality is the degree to which the results accurately
   represent the target population. If a survey’s sampling frame fully covers the population and the sample is randomly drawn from the sampling frame, a response rate of 100 % would ensure that the results are representative at a level of precision
   based on the sample size.
   - **Reporting Survey Findings**
      -  Describe the original research goals and the used survey methodology. A detailed description of the survey methodology will explain the population being studied, sampling method, survey mode, survey invitation, fielding process, and response paradata.
      - Furthermore, it is often necessary to include a discussion on how the respondents compare to the overall population.

Questions to avoid during need-finding:

1. Board questions - lack focus and include items that are not clearly defined or those that can be interpreted in multiple ways.
2. Leading questions - manipulate respondents into giving a certain answer by providing biasing content or suggesting information the researcher is looking to have confirmed.
3. Double-barreled questions - ask about multiple items while only allowing for a single response, resulting in less reliable and valid data
4. Recall questions - require the respondent to remember past attitudes and behaviors, leading to recall bias (Krosnick & Presser, 2010) and inaccurate recollections
5. Prediction questions- ask survey respondents to anticipate future behavior or attitudes, resulting in biased and inaccurate responses.

Cognitive pretesting is conducted such that the researcher can identify disconnects between their own assumptions and how respondents will read interpret, and answer questions. The pretest could be as follows:

1. “Read the entire question and describe it in your own words.”
2. “Select or write an answer while explaining your thought process.”
3. “Describe any confusing terminology or missing answer choices.”

During the data preparation and cleaning process, research should look out for the following:

1. Duplicate responses
2. Speeders
3. Straight-liners and other questionable patterns
4. Missing data and break-offs
5. Low inter-item reliability
6. Outliers

During analysis of open-ended comments, the researcher may prepare descriptive statistics such as a frequency distribution of codes, conduct inferential statistical tests, summarize key themes, prepare necessary charts,and highlight specifics through the use of representative quotes.

Similar to other empirical research, it is important to:

1. Describe the original research goals and the used survey methodology
2. Include detailed description of the survey methodology (this will explain other variables such as population being studied, etc.)
3. Discuss how the respondents compare to the overall population

Some terms from this section:

- **Survey** - method of gathering information by asking questions to a subset of people, the results of which can be generalized to the wider target population
- **Random sampling** - considered the gold standard because every person in the sampling frame has an equal, nonzero chance of being chosen for the sample
- **Confidence level** - indicates how likely the reported metric falls within the margin of error if the study were repeated
- **Satisficing** - occurs when respondents use a suboptimal amount of cognitive effort to answer questions
- **Acquiescence bias** - When presented with agree/disagree, yes/no, or true false statements, some respondents are more likely to concur with the statement independent of its substance
- **Social desirability** - occurs when respondents answer questions in a manner they feel will be positively perceived by others
- **Confidence interval** - represents the estimated range of a population’s mean at a certain confidence level
- **Linear regression** - indicates the proportion of variance in a continuous dependent variable that is explained by one or more independent variables and the amount of change explained by each unit of an independent variable
- **Coding** - used to organize and transform qualitative data from open-ended questions to enable further quantitative analysis
- **Bottom-up approach** - teh data is coded according ot categories identified by reading and re-reading responses to the open-ended question. has the benefit of capturing categories the researcher may not have thought of before reading the actual comments
