# Week 6

> Ten questions on each test will be based on these readings. From the perspective of the test, your emphasis in reading these papers should be in getting a sufficient understanding of the material to answer high-level questions about the paper, as well as to be able to find answers quickly for more specific questions.

## Section 3.4: Mental Models & Metaphor

> MacKenzie, I.S. (2013). Section 3.4: Mental Models & Metaphor. Human-Computer Interaction: An Empirical Research Perspective. (pp. 88-92). Waltham, MA: Elsevier.

Topic: mental models and metaphors.

One of the most common ways to learn and adapt is through _physical analogy_ or _metaphor_. Physical analogies and metaphors are examples of the more general concept of _mental models_, also known as _conceptual models_.

- Example is slide up->page up concept
- Mental model and How Desktop GUI came into picture - Rather than learning something new and unfamiliar, users could act out with concepts already understood: documents, folders, iling cabinets, trashcans, the top of the desk, pointing, selecting, dragging, dropping, and so on. This is the essence of mental models

- **Implementation models** - are systems that impose on the user a set of interactions that follow the inner workings of an application; they are to be avoided. Basically this wants use to use according to the application not vice versa.

### Example Human computer Interfaces
- Toolbars in GUIs are fertile ground for mental models. Example of images in toolbar trigger human thought.
- Hover the mouse pointer over a GUI button and a ield pops up providing a terse elaboration on the button’s purpose. Pop up ballons
- Another example of mental models are a compass and a clock face as metaphors for direction. Most users have an ingrained understanding of a compass and a clock. VR navigation using clock
- NaviRadar leverages users’ spatial sense of their surroundings to aid navigation. Users receive combinations of long and short vibratory pulses to indicate direction. Although the patterns must be learned, the system is simple and avoids auditory feedback, which may be impractical in some situations

## Section 3.8: Interaction Errors

> MacKenzie, I.S. (2013). Section 3.8: Interaction errors. Human-Computer Interaction: An Empirical Research Perspective. (pp. 111-116). Waltham, MA: Elsevier.

Topic: the big errors are the easy ones—they get fixed. It is the small errors that are interesting. Desktop computing is still fraught with
problems, lots of them. Let’s examine a few of thes



- Save vs Discard Error - This scenario, told by Cooper (1999, 14), is a clear and serious UI design flaw. The alert reader will quickly retort, “Yes, but if the ‘Discard changes?’ dialog box defaults to ‘No,’ the information is safe.” But that misses the point. The point is that a user expectation is broken. Broken expectations sooner or later cause errors.
- Capslock error - The capslock error is not so bad. But it’s bad enough that it occasionally receives enough attention to be the beneiciary of the few extra lines of code necessary to pop up a rsto_xkrw alert.
- Velocity of Text dragging event. 
- Focus and no focus in text box. Automatic focus move while entering phone number.
- The absence of expectations keeps the user on guard. The user is often never quite sure what to do or what to expect. The result is a slight increase in the attention demanded during interaction, which produces a slight decrease in transparency. Instead of engaging in the task, attention is diverted to the needs of the computer. The user is like a wood carver who sharpens tools rather than creates works of art.
- Microstrategies focus on what designers would regard as the
mundane aspects of interface design; the ways in which subtle features of interactive technology injuence the ways in which users perform tasks
- At the end of the day, however, human performance is what counts. Physical properties, although instructive and essential, are secondary.
- Another reason little errors tend to linger is that they are often deemed _user errors_, not design, programming, or system errors. These errors, like most, are more correctly called _design-induced errors_.

## Chapter 5: Human Error? No, Bad Design

> Norman, D. (2013). Chapter 5: Human Error? No, Bad Design. In The Design of Everyday Things: Revised and Expanded Edition. (pp. 162-216). Arizona: Basic Books.

Topic: we should treat all failures in the same way: find the fundamental causes and redesign the system so that these can no longer lead to problems.

- **Root cause analysis** - investigate the accident until the single, underlying cause is found

- **Slip** - occurs when a person intends to do one action and ends up doing something else; there are two types: _action-based_ nad _memory-lapse_
- **Mistake** - occurs when the wrong goal is established or the wrong plan is formed; there are three types: _rule-based_, _knowledge-based_, and _memory-lapse_

Key design principles for errors:

- Design for both expert and novice users
- Use the power of constraints, forcing functions, and natural mappings
- Bridge the two gulfs (execution and evaluation) by making options available and status readable and accurate

## A “Pile” Metaphor For Supporting Casual Organization Of Information

> Mander, R., Salomon, G., & Wong, Y. Y. (1992, June). A “pile” metaphor for supporting casual organization of information. In Proceedings of the SIGCHI Conference on Human Factors in Computing Systems (pp. 627-634). ACM.

Topic: investigation on how people deal with flow of information in their workspaces reveals that users organize their documents in piles thus leading into the desktop interface element - the pile (as seen on a Mac OS).

- **User-created piles** - allow users to create piles of mixed content and multiple data types
- **System-created piles** - system can create piles for a user \
- **Document-centered model** - piles represented as a collection of individual items
- **Pile-centered model** - pile acts more like a folder with a single entity containing a collection of documents
